{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e8b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import os\n",
    "import glob\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import plotly.express as px #if using plotly\n",
    "import folium\n",
    "import warnings\n",
    "import uuid\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e98b64",
   "metadata": {},
   "source": [
    "### RQ #2) Which specific flares are the most impactful? \n",
    "\n",
    "### RQ #3) Which specific block grous are being most impacted? \n",
    "\n",
    "\n",
    "Exploratory question; no hypothesis testing\n",
    "\n",
    "EJ index = (The Environmental Indicator Percentile for Block Group) x (Demographic Index for Block Group)\n",
    "  \n",
    "a) Determine flaring impact metric. \n",
    "\n",
    "Something like: buffer_population x EJ Index x flare volume  \n",
    "\n",
    "How best to normalize these different units? Use percentiles compared to rest of CA? \n",
    "\n",
    "b) Calculate impact per flare  \n",
    "\n",
    "c) Visualize top_x flares by impact  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032eabe",
   "metadata": {},
   "source": [
    "### Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ca_state = gp.read_file(\"data/CA_State_TIGER2016.shp\")  # CA state\n",
    "ca_counties = gp.read_file(\"data/CA_Counties_TIGER2016.shp\")  # CA counties\n",
    "ca_counties.rename(columns={'NAMELSAD':'cnty_name'}, inplace=True)  # old:new. Match col names for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ff8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ca_bg = gp.read_file(\"data/ca_bg_clean.shp\")  # CA block groups, cleaned\n",
    "# CA block groups merged with EJscreen data\n",
    "ca_bg_joined = gp.read_file(\"data/ca_bg_joined_clean.shp\")\n",
    "\n",
    "# update col name for correct area b/c it gets saved as a truncated version when saved as a shapefile out of the \n",
    "# main data cleaning notebook\n",
    "ca_bg_joined.rename(columns={'shape_ar_1':'shape_area_new'}, inplace=True)  # old:new.\n",
    "ca_bg_joined.rename(columns={'CNTY_NAME':'cnty_name'}, inplace=True)  # old:new.\n",
    "print(f'BGs found: {len(ca_bg_joined)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb35dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just CA flares\n",
    "ca_flares = gp.read_file(\"data/ca_flares_clean.shp\")\n",
    "\n",
    "# renaming \n",
    "ca_flares.rename(columns={'NAMELSAD':'cnty_name'}, inplace=True)  # old:new. Match col names for merging\n",
    "\n",
    "print(f'Flares found: {len(ca_flares)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flares.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set common crs for project\n",
    "# epsg3310: https://epsg.io/3310-1739\n",
    "# units: meters\n",
    "meters_crs = 3310  # Projected crs. this should be good for this overlay() calculation and all of project. \n",
    "\n",
    "ca_counties = ca_counties.to_crs(meters_crs)\n",
    "ca_flares = ca_flares.to_crs(meters_crs)\n",
    "ca_bg_joined = ca_bg_joined.to_crs(meters_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f50b2",
   "metadata": {},
   "source": [
    "### Update ca_flares df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all flares have a unique identifier â€” both CatalogID and ID columns have missing values\n",
    "# so I create a new col \"flare_id\" of IDs\n",
    "\n",
    "# generate random integer IDs\n",
    "ids = np.random.randint(100000, 999999, size=len(ca_flares))\n",
    "\n",
    "# convert integer IDs to unique string identifiers\n",
    "id_str = [str(uuid.uuid4())[:8] + str(i) for i in ids]\n",
    "\n",
    "# add the new column to the DataFrame\n",
    "ca_flares['flare_id'] = id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set col list for BCM_avg calculation\n",
    "bcm_list = ['BCM_2012','BCM_2013','BCM_2014','BCM_2015','BCM_2016','BCM_2017',\n",
    "            'BCM_2018','BCM_2019','BCM_2020','BCM_2021']\n",
    "\n",
    "# add new column for average BCM across all years\n",
    "ca_flares['BCM_avg'] = ca_flares[bcm_list].mean(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only columns needed for Tableau\n",
    "col_list = ['flare_id','flare_cate','cnty_name','BCM_2012','BCM_2013','BCM_2014','BCM_2015','BCM_2016','BCM_2017',\n",
    "            'BCM_2018','BCM_2019','BCM_2020','BCM_2021','BCM_avg', 'geometry']\n",
    "\n",
    "ca_flares_sub = ca_flares[col_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd083030",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flares_sub.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58e0f1",
   "metadata": {},
   "source": [
    "### Update ca_bg_joined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd604fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are five BGs that seem to just be aquatic buffers around the actual county land.\n",
    "# Dropping them for now \n",
    "# Explore if needed: ca_bg_joined.explore()\n",
    "\n",
    "ids_to_drop = [60839900000, 61119901000, 60379902000, 60379903000, 60599901000]\n",
    "\n",
    "# Drop the rows with those IDs\n",
    "ca_bg_joined = ca_bg_joined[~ca_bg_joined['bg_id'].isin(ids_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only cols needed\n",
    "ca_bg_joined_sub = ca_bg_joined[['bg_id', 'cnty_name', 'ACSTOTPOP', 'MINORPOP',\n",
    "                           'D_PM25_2', 'shape_area_new', 'geometry']].copy()\n",
    "\n",
    "ca_bg_joined_sub.rename(columns={'geometry':'bg_geom'}, inplace=True)  # old:new. Match col names for merging\n",
    "\n",
    "# counties_sub = ca_counties[['cnty_name', 'geometry']].copy()\n",
    "\n",
    "# counties_sub.rename(columns={'geometry':'cnty_geom'}, inplace=True)  # old:new. Match col names for merging\n",
    "\n",
    "# # add county names to social dataframe\n",
    "# ca_bg_joined_sub = pd.merge(ca_bg_joined_sub, counties_sub, \n",
    "#                              on='cnty_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533ddcd",
   "metadata": {},
   "source": [
    "### Gather data by BG and export shapefile for Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a792cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# social_df = social_df.set_geometry('bg_geom')\n",
    "\n",
    "# #flares_df = set_geometry_buffer(flares_df, buffer_size)\n",
    "# buffer_col = f\"buffer_{buffer_size}m\"\n",
    "# flares_df[buffer_col] = flares_df['geometry'].buffer(distance=buffer_size)\n",
    "\n",
    "# flares_df = flares_df.set_geometry(buffer_col)\n",
    "\n",
    "# # temp = flares_df.unary_union\n",
    "# # all_buffers = gp.GeoDataFrame({'geometry': [temp]}, crs=flares_df.crs)  # convert back to geodf for processing\n",
    "\n",
    "# test = social_df[social_df['bg_id'] == 60290033042].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d35be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_df = ca_bg_joined_sub\n",
    "flares_df = ca_flares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_df = social_df.set_geometry('bg_geom')\n",
    "\n",
    "social_df.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "flares_df.rename(columns={'geometry':'flare_pts'}, inplace=True)  # old:new. Match col names for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flares_df = set_geometry_buffer(flares_df, buffer_size)\n",
    "buffer_size=2000\n",
    "buffer_col = f\"buffer_{buffer_size}m\"\n",
    "flares_df[buffer_col] = flares_df['flare_pts'].buffer(distance=buffer_size)\n",
    "\n",
    "flares_df = flares_df.set_geometry('buffer_2000m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafe97e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flares_df.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28841c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flares_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of desired columns from flares_df\n",
    "#flares_df = flares_df.drop(['flare_pts'], axis=1)\n",
    "\n",
    "flares_subset = flares_df[['buffer_2000m', 'BCM_avg', 'flare_id']]\n",
    "\n",
    "# perform spatial join\n",
    "joined_df = gp.sjoin(social_df, flares_subset, how='left', predicate='intersects')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "flares_subset.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "flares_subset.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38684500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3d1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined_df = gp.sjoin(social_df, flares_df, how=\"left\", predicate=\"intersects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53846099",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the intersection between each block group and the buffer around each flare\n",
    "joined_df[\"intersection\"] = joined_df[\"bg_geom\"].intersection(joined_df[\"buffer_2000m\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec65a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f796a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flares_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4494ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "flaretest = flares_df[flares_df['flare_id'] == 'aa23648a650958'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flaretest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bg in test:\n",
    "    for flare in flares_df:\n",
    "        print(bg['bg_geom'], flare)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_b, bg in test.iterrows():\n",
    "    for idx_f, flare in flares_df.iterrows():\n",
    "        print(bg['bg_geom'], flare)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_temp = gp.overlay(test, flaretest, how='intersection')  # could look at keep_geom=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ad668",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9869026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "intersect_temp = gp.overlay(social_df, all_buffers, how='intersection')  # could look at keep_geom=False\n",
    "\n",
    "intersect_temp.rename(columns={'geometry':'intersect_geom'}, inplace=True)  # old:new. Match col names for merging\n",
    "\n",
    "intersect_temp = intersect_temp.set_geometry('intersect_geom')\n",
    "\n",
    "intersect_temp2 = gp.sjoin(intersect_temp, flares_df, how = \"left\", predicate = 'intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d18aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c264cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flares_new.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b685fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_final = pd.merge(intersect, \n",
    "                             ca_flares_new[['flare_id','buffer_2000m']], \n",
    "                             on=['flare_id'], \n",
    "                             how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b057a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect = intersect[['flare_id', 'bg_id', 'cnty_name','flare_cate', \n",
    "#         'BCM_2012', 'BCM_2013', 'BCM_2014', 'BCM_2015', 'BCM_2016','BCM_2017',\n",
    "#         'BCM_2018', 'BCM_2019','BCM_2020','BCM_2021','BCM_avg',\n",
    "#         'ACSTOTPOP', 'MINORPOP', 'D_PM25_2', 'shape_area_new', 'geometry']]\n",
    "\n",
    "# intersect.rename(columns={'geometry':'intersect_geom'}, inplace=True)  # old:new.\n",
    "intersect_final = intersect_final.set_geometry('intersect_geom')  # set to the buffers rather than the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d20c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new 'area' column for the areas of the intersections\n",
    "intersect_final['intersect_area'] = intersect_final.area\n",
    "\n",
    "# Calculate the proportion of each block group within the buffer zone\n",
    "intersect_final['intersect_prop'] = intersect_final['intersect_area'] / intersect_final['shape_area_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c914146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intersect_final[intersect_final['bg_id'] == 60290033042][['BCM_avg', 'bg_id', 'intersect_prop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb29143",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intersect_final['bg_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the proportion to each demographic variable to find counts by variable\n",
    "demo_vars = ['ACSTOTPOP', 'MINORPOP']\n",
    "for var in demo_vars:\n",
    "    intersect_final[var + '_intersect_count'] = intersect_final[var] * intersect_final['intersect_prop']\n",
    "\n",
    "# find overall proportions for each demo var by dividing var count by respective total population    \n",
    "for var in demo_vars:\n",
    "    intersect_final[var + '_bg_totprop'] = intersect_final[var] / intersect_final['ACSTOTPOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables to standardize\n",
    "varlist = ['BCM_avg', 'D_PM25_2', 'ACSTOTPOP_intersect_count']\n",
    "\n",
    "# Create a StandardScaler object that will transform selected variables to have a mean of zero and \n",
    "# sd of 1.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the selected variables\n",
    "intersect_norm = scaler.fit_transform(intersect_final[varlist])\n",
    "\n",
    "# Create new variables with the standardized values\n",
    "intersect_norm = pd.DataFrame(intersect_norm, columns=[var + '_norm' for var in varlist])\n",
    "\n",
    "# Concatenate the new variables with the original DataFrame\n",
    "intersect_final = pd.concat([intersect_final, intersect_norm], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shapefile for visualization in Tableau\n",
    "\n",
    "#intersect_final = intersect[['flare_id', 'flare_cate', 'bg_id', 'cnty_name', 'shape_area_new', 'intersect_prop', 'BCM_avg', 'ACSTOTPOP_intersect_count', 'D_PM25_2', 'ACSTOTPOP_intersect_count_norm', 'BCM_avg_norm', 'D_PM25_2_norm', 'intersect_geom']].copy()\n",
    "\n",
    "intersect_final.rename(columns={'shape_area_new':'shape_area'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'intersect_prop':'int_prop'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'ACSTOTPOP_intersect_count':'pop'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'ACSTOTPOP_intersect_count_norm':'pop_norm'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'BCM_avg_norm':'bcm_norm'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'D_PM25_2':'pm25'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'D_PM25_2_norm':'pm25_norm'}, inplace=True)  # old:new.\n",
    "intersect_final.rename(columns={'intersect_geom':'int_geom'}, inplace=True)  # old:new.\n",
    "\n",
    "# rename the flare categories for readability\n",
    "a = (intersect_final[\"flare_cate\"].\n",
    "                                 replace({\"flares_oil_downstream\": \"down_oil\",\n",
    "                                          \"flares_upstream\": \"upstream\"}))\n",
    "\n",
    "intersect_final = intersect_final.set_geometry('int_geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefiles can only have one geometry column\n",
    "# drop the buffer geom and flare points as they're not needed for the BG-level impact analysis. \n",
    "bg_impact = intersect_final.drop(['buffer_2000m', 'geometry'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93bbdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bg_impact.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm_bg_avg = bg_impact.groupby('bg_id')['BCM_avg'].sum().reset_index(name='bcm_bg_avg')\n",
    "\n",
    "test = pd.merge(bg_impact, bcm_bg_avg, on='bg_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['bg_id'] == 60290033042][['BCM_avg', 'bg_id', 'bcm_bg_avg', 'int_prop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7438dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[(test['bg_id'] == 60379800331) | (test['bg_id'] == 60290033042)][['BCM_avg', 'bg_id', 'bcm_bg_avg']].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b536000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bg_impact.to_file(\"data/df_bg_impactmetric_shp.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03060b1a",
   "metadata": {},
   "source": [
    "### Group by Flare ID and export shapefile for Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5fe06",
   "metadata": {},
   "source": [
    "### Create buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f798d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buffer_intersection(flares_df, social_df, buffer_size):\n",
    "    \"\"\"\n",
    "    Creates a new Geodf containing the intersection between census BGs\n",
    "    and buffers of {buffer size} around flare sites.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flares_df : A Geodf containing point geometries representing flare sites.\n",
    "    social_df : A Geodf containing polygon geometries representing social data from EPA EJScreen\n",
    "    buffer_size : int\n",
    "        The size of the buffer around each flare site, in meters.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of GeoDataFrames\n",
    "        A tuple containing two GeoDataFrames:\n",
    "        1. The original flares_df with a new buffer column added.\n",
    "        2. A GeoDataFrame containing the intersection between social_df and the \n",
    "        union of all buffer geometries in flares_df.\n",
    "    \"\"\"\n",
    "    \n",
    "    social_df = social_df.set_geometry('bg_geom')\n",
    "    \n",
    "    #flares_df = set_geometry_buffer(flares_df, buffer_size)\n",
    "    buffer_col = f\"buffer_{buffer_size}m\"\n",
    "    flares_df[buffer_col] = flares_df['geometry'].buffer(distance=buffer_size)\n",
    "\n",
    "    flares_df = flares_df.set_geometry(buffer_col)\n",
    "    \n",
    "    temp = flares_df.unary_union\n",
    "    all_buffers = gp.GeoDataFrame({'geometry': [temp]}, crs=flares_df.crs)  # convert back to geodf for processing\n",
    "    \n",
    "    intersect_temp = gp.overlay(social_df, all_buffers, how='intersection')  # could look at keep_geom=False\n",
    "    \n",
    "    intersect_temp.rename(columns={'geometry':'intersect_geom'}, inplace=True)  # old:new. Match col names for merging\n",
    "    \n",
    "    intersect_temp = intersect_temp.set_geometry('intersect_geom')\n",
    "\n",
    "    intersect_temp2 = gp.sjoin(intersect_temp, flares_df, how = \"left\", predicate = 'intersects')\n",
    "\n",
    "    return flares_df, intersect_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_sizes = [2000]\n",
    "#buffer_sizes = [100, 400, 800, 1000, 1600, 2000, 5000, 7500, 10000]\n",
    "\n",
    "for buffer_size in buffer_sizes:\n",
    "    ca_flares_new, intersect = create_buffer_intersection(ca_flares_sub, ca_bg_joined_sub, buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409dc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flares_new.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbdb00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intersect_final.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab only necessary cols\n",
    "intersect_forflares = intersect_final[['flare_id','bg_id', 'cnty_name_left', 'flare_cate',\n",
    "                                 'BCM_2012', 'BCM_2013', 'BCM_2014', 'BCM_2015','BCM_2016', \n",
    "                                 'BCM_2017', 'BCM_2018', 'BCM_2019', 'BCM_2020', 'BCM_2021','BCM_avg',\n",
    "                                 'buffer_2000m','pop','pm25','bcm_norm']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables to aggregate\n",
    "agg_dict = {'pm25': 'mean', 'pop': 'sum'}\n",
    "\n",
    "# Group the block groups by flare ID and calculate the aggregation for the variables\n",
    "ca_flares_agg = intersect_forflares.groupby('flare_id').agg(agg_dict)\n",
    "\n",
    "# Rename the output variables\n",
    "ca_flares_agg = ca_flares_agg.rename(columns={'pm25': 'pm25_avg', 'pop': 'pop_sum'})\n",
    "\n",
    "# Join the aggregated variables with the original columns\n",
    "ca_flares_merged = intersect_forflares.merge(ca_flares_agg, on='flare_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables to standardize\n",
    "varlist = ['pm25_avg', 'pop_sum']  # because bcm is already attached to the flare unit of analysis\n",
    "\n",
    "# Create a StandardScaler object that will transform selected variables to have a mean of zero and \n",
    "# sd of 1.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the selected variables\n",
    "intersect_norm = scaler.fit_transform(ca_flares_merged[varlist])\n",
    "\n",
    "# Create new variables with the standardized values\n",
    "intersect_norm = pd.DataFrame(intersect_norm, columns=[var + '_n' for var in varlist])\n",
    "\n",
    "# Concatenate the new variables with the original DataFrame\n",
    "ca_flares_merged_f = pd.concat([ca_flares_merged, intersect_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb3f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ca_flares_merged_f.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb354e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flares_merged_f = gp.GeoDataFrame(ca_flares_merged_f, geometry='buffer_2000m', crs=meters_crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flares_merged_f.to_file(\"data/df_flare_impactmetric_shp.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaaafeb",
   "metadata": {},
   "source": [
    "## Calculating single instance of weights here in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for each variable\n",
    "bcm_weight = 0\n",
    "pm25_weight = 1\n",
    "pop_weight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea12358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted variables\n",
    "intersect['BCM_weighted'] = intersect['BCM_avg_norm'] * bcm_weight\n",
    "intersect['D_PM25_2_weighted'] = intersect['D_PM25_2_norm'] * pm25_weight\n",
    "intersect['ACSTOTPOP_weighted'] = intersect['ACSTOTPOP_intersect_count_norm'] * pop_weight\n",
    "\n",
    "# Define the variables to sum\n",
    "varlist_weighted = ['BCM_weighted', 'D_PM25_2_weighted', 'ACSTOTPOP_weighted']\n",
    "\n",
    "# Group the block groups by flare ID and sum the weighted variables\n",
    "ca_flares_merged = intersect.groupby('flare_id')[varlist_weighted].sum()\n",
    "\n",
    "# Calculate the impact metric as the sum of the weighted variables\n",
    "ca_flares_merged['impact_metric'] = ca_flares_merged[varlist_weighted].sum(axis=1)\n",
    "\n",
    "# Sort the flares by impact metric in descending order\n",
    "ca_flares_merged = ca_flares_merged.sort_values('impact_metric', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "ca_flares_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the variables to sum\n",
    "# varlist_norm = ['BCM_avg_norm', 'D_PM25_2_norm', 'ACSTOTPOP_intersect_count_norm']\n",
    "\n",
    "# # Group the block groups by flare ID and sum the standardized variables\n",
    "# ca_flares_merged = intersect.groupby('flare_id')[varlist_norm].sum()\n",
    "\n",
    "# # Calculate the impact metric as the sum of the standardized variables\n",
    "# ca_flares_merged['impact_metric'] = ca_flares_merged[varlist_norm].sum(axis=1)\n",
    "\n",
    "# # Sort the flares by impact metric in descending order\n",
    "# ca_flares_merged = ca_flares_merged.sort_values('impact_metric', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(ca_flares_merged, intersect, on='flare_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78391a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_geoms = df_final[~df_final.is_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85daf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for use in tableau\n",
    "df_final.to_csv(F\"data/df_impactmetric_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e18752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values\n",
    "# missing_values = df_final.isnull().sum()\n",
    "\n",
    "# # filter columns with missing values\n",
    "# missing_cols = missing_values[missing_values > 0]\n",
    "\n",
    "# # print column names and number of missing values\n",
    "# for col in missing_cols.index:\n",
    "#     print(f\"Column '{col}' has {missing_cols[col]} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adf23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_missing = missing_values[missing_values == 0]\n",
    "# # print column names and number of missing values\n",
    "# for col in no_missing.index:\n",
    "#     print(f\"Column '{col}' has {no_missing[col]} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ef0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_final.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display the top ten flares by impact metric\n",
    "# top_ten = for_map.nlargest(10, 'impact_metric')\n",
    "# top_ten = top_ten.set_geometry('buffer_2000m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305ac9e",
   "metadata": {},
   "source": [
    "## Top ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing values\n",
    "# missing_values = for_map.isnull().sum()\n",
    "\n",
    "# # filter columns with missing values\n",
    "# missing_cols = missing_values[missing_values > 0]\n",
    "\n",
    "# # print column names and number of missing values\n",
    "# for col in missing_cols.index:\n",
    "#     print(f\"Column '{col}' has {missing_cols[col]} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0547bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_missing = missing_values[missing_values == 0]\n",
    "# # print column names and number of missing values\n",
    "# for col in no_missing.index:\n",
    "#     print(f\"Column '{col}' has {no_missing[col]} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7ac9a",
   "metadata": {},
   "source": [
    "## Folium Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf814d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_map = df_final[['flare_id', 'BCM_avg', 'D_PM25_2', 'ACSTOTPOP_intersect_count', 'impact_metric', 'buffer_2000m']]\n",
    "for_map = gp.GeoDataFrame(for_map, geometry='buffer_2000m', crs=meters_crs)\n",
    "\n",
    "for_map.to_file(\"data/df_impactmetric_shp.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the color scale and number of bins\n",
    "color_scale = 'Reds'\n",
    "num_bins = 10\n",
    "\n",
    "# Create a map centered on the first flare\n",
    "# Create a folium map with a center location\n",
    "m = folium.Map(location=[38.377158,-121.645792], zoom_start=6, tiles=None,overlay=False)  #start w lat/long roughly in center of CA\n",
    "base_map = folium.FeatureGroup(name='Base map', overlay=True, control=False)\n",
    "folium.TileLayer(tiles='OpenStreetMap').add_to(base_map)\n",
    "base_map.add_to(m)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a choropleth layer\n",
    "folium.Choropleth(\n",
    "    geo_data=for_map,\n",
    "    name='Impact Metric',\n",
    "    data=for_map,\n",
    "    columns=['flare_id', 'BCM_avg', 'D_PM25_2', \n",
    "             'ACSTOTPOP_intersect_count', 'impact_metric', 'buffer_2000m'],\n",
    "    key_on='feature.properties.flare_id',\n",
    "    fill_color=color_scale,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    bins=num_bins,\n",
    "    legend_name='Impact Metric'\n",
    ").add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d791795",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_function = lambda x: {'fillColor': '#ffffff', \n",
    "                            'color':'#000000', \n",
    "                            'fillOpacity': 0.1, \n",
    "                            'weight': 0.1}\n",
    "highlight_function = lambda x: {'fillColor': '#999999', \n",
    "                                'color':'#999999', \n",
    "                                'fillOpacity': 0.50, \n",
    "                                'weight': 0.1}\n",
    "NIL = folium.features.GeoJson(\n",
    "    data = for_map,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=['flare_id', 'BCM_avg_norm', 'D_PM25_2_norm', \n",
    "             'ACSTOTPOP_intersect_count_norm', 'impact_metric'],# 'D_PM25_2', 'ACSTOTPOP', 'MINORPOP','shape_area_new', 'intersect_prop', 'intersect_area', 'MINORPOP_bg_totprop'],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hover functionality as child to map, add layering, display map\n",
    "m.add_child(NIL)\n",
    "m.keep_in_front(NIL)\n",
    "folium.LayerControl().add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d328391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstonermi37",
   "language": "python",
   "name": "capstonermi37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
